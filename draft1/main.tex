%File: anonymous-submission-latex-2024.tex
\documentclass[letterpaper]{article} % DO NOT CHANGE THIS
\usepackage[submission]{aaai24}  % DO NOT CHANGE THIS
% \usepackage{aaai24}
\usepackage{times}  % DO NOT CHANGE THIS
\usepackage{helvet}  % DO NOT CHANGE THIS
\usepackage{courier}  % DO NOT CHANGE THIS
\usepackage[hyphens]{url}  % DO NOT CHANGE THIS
\usepackage{graphicx} % DO NOT CHANGE THIS
\graphicspath{ {./images/} }
\urlstyle{rm} % DO NOT CHANGE THIS
\def\UrlFont{\rm}  % DO NOT CHANGE THIS
\usepackage{natbib}  % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\usepackage{caption} % DO NOT CHANGE THIS AND DO NOT ADD ANY OPTIONS TO IT
\frenchspacing  % DO NOT CHANGE THIS
\setlength{\pdfpagewidth}{8.5in} % DO NOT CHANGE THIS
\setlength{\pdfpageheight}{11in} % DO NOT CHANGE THIS
%
% These are recommended to typeset algorithms but not required. See the subsubsection on algorithms. Remove them if you don't have algorithms in your paper.
\usepackage{algorithm}
\usepackage{algorithmic}

% Custom packages
\usepackage{tikz}
\usepackage[inline]{enumitem}
\usepackage{pifont}  % for the checkmark/crossmark
\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=.6pt] (char) {#1};}}
%
% These are are recommended to typeset listings but not required. See the subsubsection on listing. Remove this block if you don't have listings in your paper.
\usepackage{newfloat}
\usepackage{listings}
\DeclareCaptionStyle{ruled}{labelfont=normalfont,labelsep=colon,strut=off} % DO NOT CHANGE THIS
\lstset{%
	basicstyle={\footnotesize\ttfamily},% footnotesize acceptable for monospace
	numbers=left,numberstyle=\footnotesize,xleftmargin=2em,% show line numbers, remove this entire line if you don't want the numbers.
	aboveskip=0pt,belowskip=0pt,%
	showstringspaces=false,tabsize=2,breaklines=true}
\floatstyle{ruled}
\newfloat{listing}{tb}{lst}{}
\floatname{listing}{Listing}
%
% Keep the \pdfinfo as shown here. There's no need
% for you to add the /Title and /Author tags.
\pdfinfo{
/TemplateVersion (2024.1)
}

% DISALLOWED PACKAGES
% \usepackage{authblk} -- This package is specifically forbidden
% \usepackage{balance} -- This package is specifically forbidden
% \usepackage{color (if used in text)
% \usepackage{CJK} -- This package is specifically forbidden
% \usepackage{float} -- This package is specifically forbidden
% \usepackage{flushend} -- This package is specifically forbidden
% \usepackage{fontenc} -- This package is specifically forbidden
% \usepackage{fullpage} -- This package is specifically forbidden
% \usepackage{geometry} -- This package is specifically forbidden
% \usepackage{grffile} -- This package is specifically forbidden
% \usepackage{hyperref} -- This package is specifically forbidden
% \usepackage{navigator} -- This package is specifically forbidden
% (or any other package that embeds links such as navigator or hyperref)
% \indentfirst} -- This package is specifically forbidden
% \layout} -- This package is specifically forbidden
% \multicol} -- This package is specifically forbidden
% \nameref} -- This package is specifically forbidden
% \usepackage{savetrees} -- This package is specifically forbidden
% \usepackage{setspace} -- This package is specifically forbidden
% \usepackage{stfloats} -- This package is specifically forbidden
% \usepackage{tabu} -- This package is specifically forbidden
% \usepackage{titlesec} -- This package is specifically forbidden
% \usepackage{tocbibind} -- This package is specifically forbidden
% \usepackage{ulem} -- This package is specifically forbidden
% \usepackage{wrapfig} -- This package is specifically forbidden
% DISALLOWED COMMANDS
% \nocopyright -- Your paper will not be published if you use this command
% \addtolength -- This command may not be used
% \balance -- This command may not be used
% \baselinestretch -- Your paper will not be published if you use this command
% \clearpage -- No page breaks of any kind may be used for the final version of your paper
% \columnsep -- This command may not be used
% \newpage -- No page breaks of any kind may be used for the final version of your paper
% \pagebreak -- No page breaks of any kind may be used for the final version of your paperr
% \pagestyle -- This command may not be used
% \tiny -- This is not an acceptable font size.
% \vspace{- -- No negative value may be used in proximity of a caption, figure, table, section, subsection, subsubsection, or reference
% \vskip{- -- No negative value may be used to alter spacing above or below a caption, figure, table, section, subsection, subsubsection, or reference

\setcounter{secnumdepth}{0} %May be changed to 1 or 2 if section numbers are desired.

% The file aaai24.sty is the style file for AAAI Press
% proceedings, working notes, and technical reports.
%

% Title

% Your title must be in mixed case, not sentence case.
% That means all verbs (including short verbs like be, is, using,and go),
% nouns, adverbs, adjectives should be capitalized, including both words in hyphenated terms, while
% articles, conjunctions, and prepositions are lower case unless they
% directly follow a colon or long dash
\title{FedKit: Enabling Cross-Platform Federated Learning for Android and iOS}
\author{
    Sichang He\textsuperscript{\rm 1},
    Beilong Tang\textsuperscript{\rm 1},
    Boyang Zhang\textsuperscript{\rm 1},
    Jiaqi Shao\textsuperscript{\rm 1} \textsuperscript{\rm 2},
    \\
    Xiaomin Ouyang\textsuperscript{\rm 3},
    Daniel Nata Nugraha\textsuperscript{\rm 4},
    Bing Luo\textsuperscript{\rm 1}
}
\affiliations{
    \textsuperscript{\rm 1}Data Science Research Center,
        Duke Kunshan University, Jiangsu, China\\
    \textsuperscript{\rm 2}Department of Electronic and Computer Engineering,
        The Hong Kong University of Science and Technology, China\\
    \textsuperscript{\rm 3}Department of Electrical and Computer Engineering,
        University of California, Los Angeles, USA\\
    \textsuperscript{\rm 4}
        Flower Labs GmbH, Winterhuder Weg 29, 22085 Hamburg, Germany\\
    \{sichang.he, beilong.tang, boyan.zhang\}@dukekunshan.edu.cn,
    jiaqi.shao@connect.ust.hk,
    xmouyang19@gmail.com,
    daniel.nata@flower.dev,
    bing.luo@dukekunshan.edu.cn
}

\begin{document}

\maketitle

\begin{abstract}
    % "Federated learning" is an ordinary word combination.
    We present FedKit, a federated learning (FL) system tailored for
    cross-platform FL research on \textit{Android and iOS} devices.
    FedKit pipelines FL development by
    % This is the first time model appears, so we should say "ML."
    enabling machine learning (ML) model conversion,
    hardware-accelerated training,
    and cross-platform model aggregation.
    Our FL workflow supports flexible ML operations (MLOps) in production,
    facilitating continuous model delivery and training.
    We have deployed FedKit in a real-world use case for
    exercise data analysis on campus,
    demonstrating its effectiveness.
    FedKit is open-source at \url{https://github.com/FedCampus/FedKit}.
\end{abstract}

\section{Introduction}

Federated learning (FL) enables edge devices to
collaboratively train a shared machine learning (ML) model while
retaining private data on the device \cite{mcmahan2017communication}.
Smartphones, rich in sensitive data,
are promising candidates for FL.
Nevertheless, most existing FL systems
\cite[e.g.,][]{bonawitz2019towards,liu2021fate,ma2019paddlepaddle,openfl_citation}
primarily cater to simulation,
limiting their practical use on smartphones for research and applications.

Several systems have emerged to fulfill on-smartphone FL,
but still exhibit limitations,
as shown in Table~\ref{tbl:fn-systems}.
Specifically, FedML \cite{he2020fedml},
Project Florida \cite{madrigal2023project},
and FedScale \cite{lai2022fedscale} primarily support Android.
On the other hand,
Flower \cite{beutel2020flower,mathur2021ondevice} and
Syft \cite{ryffel2018generic,Ziller2021,hall2021syft}
provide SDKs for both Android and iOS.
However, Flower SDKs lack support for on-device training and
cross-platform aggregation,
while Syft lacks hardware acceleration for on-device training.

In addition to seamless cross-platform support,
customizable and continuous deployment in production is crucial.
While FedML and Florida support ML operations (MLOps),
their proprietary services limit full customization.
In contrast, open-source solutions like Flower and Syft enable
full customization
but are more suitable for single experiments rather than continuous deployment.

\subsubsection{Contributions}
We developed FedKit,
a versatile FL system designed to enable \textbf{cross-platform} FL research on
\textbf{Android and iOS}:
\begin{enumerate}[label=$\bullet$]
    \item FedKit provides \textbf{modularized libraries} to train
        Python-based models on Android and iOS and
        aggregate them across platforms.
        These libraries can serve as a foundational resource for
        on-device ML systems.
    \item The FL workflow in FedKit
        enables flexible \textbf{MLOps} from
        the Backend in production.
        This innovation encourages other open-source solutions to
        rival proprietary services in deployment support.
\end{enumerate}

\section{System Description}

FedKit facilitates FL among Android and iOS clients (mobile apps),
coordinated by a single Backend server.
Each client trains a local model with private data,
and the Backend performs cross-platform aggregation of these local models to update the global model.
Specifically, FedKit introduces two key innovations: 
\circled{1} A cross-platform (Android-iOS) FL pipeline centered around ML models.
\circled{2} Flexible MLOps to enable efficient FL research iteration in production.

\begin{table}
    \centering
    \small
    \setlength{\tabcolsep}{2pt}
    \begin{tabular}{lccccc}
        Functionality        & FedML      & Florida    & Flower     & Syft       & \textbf{FedKit} \\
        \hline
        Android-Only         & \ding{51}  & \ding{51}  & \ding{51}  & \ding{51}  & \ding{51}       \\
        iOS-Only             & \ding{55}  & \ding{55}  & \ding{51}  & \ding{51}  & \ding{51}       \\
        Cross-Platform Aggr. & \ding{55}  & \ding{55}  & \ding{55}  & \ding{51}  & \ding{51}       \\
        \hline
        Training Acceleration& \ding{51}  & \ding{51}  & \ding{51}  & \ding{55}  & \ding{51}       \\
        MLOps                & \ding{51}  & \ding{51}  & \ding{55}  & \ding{55}  & \ding{51}       \\
        Open-Source Backend  & \ding{55}  & \ding{55}  & \ding{51}  & \ding{51}  & \ding{51}       \\
    \end{tabular}
    \caption{Functionality Comparison among On-Smartphone FL Systems.
    }
    \label{tbl:fn-systems}
\end{table}

\subsection{Cross-Platform FL Model Pipeline}

To enable cross-platform FL,
especially \textit{cross-platform aggregation},
we propose a pipeline comprising
\textit{model conversion} and
\textit{unified training APIs},
as shown in Fig.~\ref{cross_fl}.

\begin{figure}
    \centering
    \includegraphics*[width=\linewidth]{model_pipeline.pdf}
    \caption{FedKit Model Pipeline for Cross-Platform FL.}
    \label{cross_fl}
\end{figure}

\subsubsection{Model Conversion}
We begin in Python by converting models into formats compatible with
Android (TensorFlow Lite or TFLite) and iOS (Core ML).
Core ML defines a fixed model structure and provides
the official converter CoreMLTools.
For TFLite, we \textit{standardized} a model format and
developed a compliant TensorFlow converter.
This standardized format includes
four essential FL methods
(\lstinline{train}, \lstinline{infer}, \lstinline{parameters},
and \lstinline{restore}).


\subsubsection{Unified Training APIs}
FedKit provides \textit{TFLite Trainer} and \textit{Core ML Trainer} to
train the converted models on Android and iOS devices,
utilizing GPU and NPU acceleration.
Moreover, both trainers expose unified APIs for
\textit{retrieving and setting model parameters,
model fitting, and evaluation}.
On Android, these APIs invoke the TFLite interpreter to call
our \textit{standardized methods} defined in \textit{Model Conversion}.
However, on iOS, our experimentation revealed that
Core ML \textit{forbids} directly setting parameters, which could impede FL.
To overcome this constraint,
we modify the underlying ProtoBuf representations of
Core ML models.
Specifically,
we employ Swift code generated from the relevant ProtoBuf definition files,
and navigate nested model definitions to access parameters on iPhones.
Consequently, our unified training APIs exhibit comparable functionality on
both iOS and Android platforms.


\subsubsection{Cross-Platform Aggregation}
Aggregation necessitates
\textit{uniform parameter representations},
which poses primary challenges in
retrieving and setting parameters for TFLite and Core ML.
1)
The TFLite interpreter only accepts inputs/outputs as maps from \textit{names} to
\textit{tensors}.
Consequently, during \textit{Model Conversion},
we assign index-based names to each parameter layer and
dynamically generate the concrete methods that accept these arguments.
During training, we call the methods with these index-based names to
access parameters.
2)
Core ML permits \textit{only} specific layers to be \textit{updatable} and
only provides their parameters post-training.
Thus, to obtain \textit{other layers'} parameters,
we implemented a solution using ProtoBuf manipulation.
This approach involves recording layer information
during \textit{Model Conversion} and
utilizing it during training.
Finally, these unified parameters enable seamless cross-platform aggregation.

\subsection{Flexible MLOps in Production}
\newcommand{\model}{$M$}
\newcommand{\fs}{$S_\mathrm F$}
FedKit empowers researchers to deploy models and algorithms continuously (MLOps)
in production.
Leveraging our complete control of the self-hosted Backend,
FedKit's three-step FL workflow, illustrated in (Fig.~\ref{fig:fl-workflow}),
facilitates continuous delivery and training.
\subsubsection{Continuous Cross-Platform Model Delivery}
Traditionally, models for on-device training are \textit{embedded} into client apps.
However, this approach couples model delivery with app updates, 
resulting in complexities when submitting apps to app stores and garnering user adoption.

Circumventing this complexity,
FedKit enables \textit{continuous model delivery without app updates} by
decoupling models from clients through \textit{Model Request},
which allows new model deployment by uploading to the Backend.
Specifically, clients request the Backend for a model (TFLite/Core ML)
aligned with
their platform (Android/iOS) and training data type.
The Backend selects the appropriate model \model{} from the database and
responds with detailed model information.
Consequently, \textit{Model Request} delivers the TFLite or Core ML model
to clients for FL training.

\subsubsection{Customizable Continuous FL Training}
FedKit manages continuous FL training by allowing \textit{multiple parallel FL training sessions}
through \textit{FL Server Setup}.
When clients request an FL Server to
train their chosen model \model{},
the Backend either reuses a suitable FL Server \fs{} if it exists,
or spawns a new one.
Each FL Server
operates as an independent Python subprocess of the Django Backend,
occupying its own port that
clients connect to for FL Training.
This dynamic approach ensures that
newly delivered models can be immediately trained with new FL Servers
without affecting ongoing ones.
Furthermore,
these FL Servers employ the Flower FL Framework for
scheduling training and evaluation.
This decision empowers our FL Servers to leverage Flower's flexibility and
allow for FL algorithm customizations in Python.

\begin{figure}
    \centering
    \includegraphics*[width=0.9\linewidth]{fl_workflow.pdf}
    \caption{FedKit FL Workflow.}
    \label{fig:fl-workflow}
\end{figure}

\section{Use Case: FedCampus}

\begin{figure}
    \centering
    \includegraphics*[width=0.9\linewidth]{fedcampus.pdf}
    \caption{FedCampus Experiment Setup.}
    \label{fig:fedcampus}
\end{figure}

We applied FedKit to a practical use case, FedCampus,
utilizing a mobile app to harness exercise data on a university campus.
This context demanded Android, iOS, and cross-platform aggregation support.
Additionally,
FL on mobile devices necessitates training acceleration for
a smooth user experience
and MLOps to facilitate iterative model design.

In the FedCampus experiment setup (Fig.~\ref{fig:fedcampus}),
we self-hosted the Backend
and displayed the real-time logs and losses on a connected laptop.
Our app, powered by FedKit,
performed FL across Android and iOS devices,
training a sleep-efficiency prediction model
akin to \cite{khoa2022fedmcrnn}
using data from the smartwatches.
The results showcased a significant reduction in the model's training loss,
demonstrating FedKit's effectiveness in real-world scenarios.

\appendix

\section*{Acknowledgments}
We would like to thank Flower Labs for the discussion on on-device training.
We also thank undergraduate student Renyuan Zhang,
who participated in the project.

\bigskip

\bibliography{main}

\end{document}
